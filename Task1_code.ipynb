{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input the file path hereC:\\Users\\AKSHAR\\Desktop\\Factentry project\\Factentry files\\IT0005220998.pdf\n",
      "What term are you looking forspecified denominations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AKSHAR\\Anaconda3\\envs\\BEST ENVIRONMENT\\lib\\site-packages\\fuzzywuzzy\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "path=str(input('Input the file path here'))\n",
    "term=str(input('What term are you looking for'))\n",
    "#importing all the required libraries\n",
    "#C:\\Users\\AKSHAR\\Desktop\\Factentry project\\Factentry files\\CA136375CR16.pdf\n",
    "import nltk\n",
    "import io\n",
    "from fuzzywuzzy import fuzz\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "from price_parser import Price\n",
    "from pdfminer3.layout import LAParams, LTTextBox\n",
    "from pdfminer3.pdfpage import PDFPage\n",
    "from pdfminer3.pdfinterp import PDFResourceManager\n",
    "from pdfminer3.pdfinterp import PDFPageInterpreter\n",
    "from pdfminer3.converter import PDFPageAggregator\n",
    "from pdfminer3.converter import TextConverter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file=open(path,'rb')\n",
    "resource_manager = PDFResourceManager()\n",
    "fake_file_handle = io.StringIO()\n",
    "converter = TextConverter(resource_manager, fake_file_handle, laparams=LAParams())\n",
    "page_interpreter = PDFPageInterpreter(resource_manager, converter)\n",
    "\n",
    "with file as fh:\n",
    "    for page in PDFPage.get_pages(fh,\n",
    "                                  caching=True,\n",
    "                                  check_extractable=True):\n",
    "        page_interpreter.process_page(page)\n",
    "    text = fake_file_handle.getvalue()\n",
    "\n",
    "#close open handles\n",
    "converter.close()\n",
    "fake_file_handle.close()\n",
    "words=text\n",
    "#print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing unnecessary characters and tokenizing the words\n",
    "pg1=words\n",
    "from nltk.tokenize import RegexpTokenizer \n",
    "def remove_characters(x):\n",
    "    tk = RegexpTokenizer(r\"\\s|[\\.;#']\", gaps = True) \n",
    "    return tk.tokenize(x) \n",
    "tokenized_words = remove_characters(str(pg1))\n",
    "#print(tokenized_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58\n",
      "must be read in conjunction with the Base Prospectus Full information on the Issuer, the Guarantor and the offer of\n",
      "-------------------------------------------------\n",
      "65\n",
      "of the Aggregate Nominai Amount (i) (ii) (i) (ii) Specified Denominations: Calculation Amount: Issue Date: € 100,000 € 100,000 28\n",
      "-------------------------------------------------\n",
      "The Sentence with Highest ratio is:\n",
      "**************************************************************\n",
      "of the Aggregate Nominai Amount (i) (ii) (i) (ii) Specified Denominations: Calculation Amount: Issue Date: € 100,000 € 100,000 28\n",
      "**************************************************************\n"
     ]
    }
   ],
   "source": [
    "#Finding the sentences where the word might occur\n",
    "max_ratio=0\n",
    "sentence=''\n",
    "letter=0\n",
    "for i in range(0,len(tokenized_words)):\n",
    "    ratio = fuzz.ratio(tokenized_words[i],'minimum denomination')\n",
    "    if ratio>40:\n",
    "        if ratio>max_ratio:\n",
    "            sentence=' '.join(tokenized_words[i-10:i+10])\n",
    "            print(ratio)\n",
    "            print(sentence)\n",
    "            print('-------------------------------------------------')\n",
    "            letter=i\n",
    "            max_ratio=ratio\n",
    "print('The Sentence with Highest ratio is:')\n",
    "print('**************************************************************')\n",
    "print(sentence)\n",
    "print('**************************************************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price(amount=Decimal('100000'), currency='€')\n",
      "The value for specified denominations is 100000\n"
     ]
    }
   ],
   "source": [
    "#Retrieving the price and currency\n",
    "price = Price.fromstring(sentence)\n",
    "print(price)\n",
    "print('The value for',term,'is',price.amount)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
